{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "A `Corpus` is the main source of data in `retrievall`—the thing that you retrieve *from*.\n",
    "\n",
    "[The term *corpus*](https://en.wikipedia.org/wiki/Text_corpus) (plural: *corpora*) is commonly used in the fields of linguistics and more traditional information retrieval/natural language processing to refer to a dataset or collection of documents.\n",
    "\n",
    "Retrievall uses this word in the same sense: it's the collection of documents or data that you want to retrieve from. This collection can be large (e.g. thousands of documents, all of Wikipedia), but it can also be small (e.g. a single PDF, a single text string)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation\n",
    "Many RAG libraries represent corpora and documents (and chunks of documents) in a top-down way, where you your documents are what they are and you retrieve from them as-is: you either retrive the full content of a document, or you maybe desctructively break the document down into smaller chunks that *replace* your documents as new, smaller documents.\n",
    "\n",
    "In retrievall, a corpus and its documents are represented from the *bottom up*. Rather than storing documents as-is in fixed configurations, a `Corpus` stores the smallest constituent parts of all its documents (referred to as as **`atom`s**—e.g. individual OCR tokens, individual strings), and then deals with arbitrary *collections* of these atoms.\n",
    "\n",
    "Rather than distinct documents, a `Corpus` is like a big soup of all the atoms in all the documents of the corpus. This means that the atoms can be freely rearranged or reassociated into new collections on-the-fly to \"chunk\" the corpus in new ways. Even \"documents\" themselves are just collections of atoms (or \"chunks\"), which means that a full document, or a paragraph, or a 100-token rolling window, or even single-token spans all have the same primacy and representation. You can easily switch between different \"chunking\" methods to retrieve exactly what you're looking for, whether thats something big or something really little.\n",
    "\n",
    "See [here](02_chunks.ipynb) for more details on chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation\n",
    "A `Corpus` is instantiated with a `atoms` PyArrow `Table`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atoms\n",
    "At the *bare minimum*, atoms all need an `id` column, with a distinct identifier value for each atom. The there is no prescribed data type for IDs—any type is allowed, but some types may be easier to use or more performant that others.\n",
    "\n",
    "Atoms can also have any kind of \"attributes\" or metadata. For example, text-based tokens will have a `text` column (and likely an `ordinal` column to stipulate reading order). Similarly, OCR-based atoms may have location or bounding box information to pinpoint where they exist on document pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<retrievall.core.Corpus at 0x108b0cca0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "from retrievall import Corpus\n",
    "\n",
    "atoms = pa.Table.from_pydict(\n",
    "    {\n",
    "        \"id\": [123, 355, 684, 235, 407],  # Literally putting random values here.\n",
    "        \"text\": [\"Lorem\", \"ipsum\", \"dolor\", \"sit\", \"amet\"],\n",
    "        \"ordinal\": [1, 2, 3, 4, 5],\n",
    "    }\n",
    ")\n",
    "\n",
    "corpus = Corpus(atoms=atoms)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus chunks\n",
    "Instantiation creates an empty `chunks` dictionary as an attribute of the `Corpus`. This is where all chunk information is stored and accessible. Note that not all useful chunks *need* to be stored in the corpus—in plenty of cases, it's fine to chunk on-the-fly and then throw the chunks away after you get what you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding persistent chunks\n",
    "A `Corpus` cannot be *created* with chunks at instantiation time; chunks must be added to the corpus' chunk dict separately, after instantiation. The easiest way to do this is via `Corpus.set_chunk`.\n",
    "\n",
    "Any chunks added to the corpus` chunk dict can be thought of as \"persistent\"—since they're stored in the corpus, you can acces the contents of the chunks again and again without having to re-run any chunking-related computations.\n",
    "\n",
    "As an example, note that our `corpus` object from earlier in the notebook doesn't have any chunks whatsoever. One rgeally common chunk to set up is a `document` chunk, which tells us which atoms are in which document(s) in our corpus; in this case, we only have one document, but a corpus may have many.\n",
    "\n",
    "Let's manually add `document` chunks to this corpus. (See the [`Chunks` documentation](02_chunks.ipynb) for details about instantiating `Chunks` objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': <retrievall.core.Chunks at 0x108a39420>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from retrievall import Chunks\n",
    "\n",
    "# *Very* manually create our document chunks\n",
    "doc_chunks = Chunks(\n",
    "    corpus=corpus,\n",
    "    chunks=pa.Table.from_pydict({\"id\": [1234]}),\n",
    "    chunk_atoms=pa.Table.from_pydict(\n",
    "        {\"chunk\": [1234, 1234, 1234, 1234, 1234], \"atom\": [123, 355, 684, 235, 407]}\n",
    "    ),\n",
    ")\n",
    "\n",
    "corpus.set_chunk(name=\"document\", chunks=doc_chunks)\n",
    "\n",
    "# Manually check the updated chunk dict\n",
    "corpus.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve relevant `document`s in the future without having to re-determine which atoms belong to which document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ephemeral chunks\n",
    "Chunks that are used for one-off calculations or retrieval processes, which don't need to be stored long-term, can be thought about as \"ephemeral\" chunks. You can create ephemeral chunks from a chunker by passing a `ChunkExpr` to a corpus' `Corpus.chunk` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<retrievall.core.Chunks at 0x10e539540>, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from retrievall.chunkers import FixedSizeChunk\n",
    "\n",
    "fixed_chunks = corpus.chunk(FixedSizeChunk(\"document\", 4, offset=-2))\n",
    "fixed_chunks, len(fixed_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that many chunk expressions may require referencing some kind of existing chunk—in this case, we used `document`s as the boundaries of our fixed-size windows.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the corpus, we can see that no new chunks were added, and that these fixed size chunks were just temporary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': <retrievall.core.Chunks at 0x108a39420>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to persist these initially-ephermeral chunks to the corpus, we could pass our ephemeral chunks to `Corpus.set_chunk`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': <retrievall.core.Chunks at 0x108a39420>,\n",
       " 'my_fixed_chunk': <retrievall.core.Chunks at 0x108a86920>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.set_chunk(\n",
    "    \"my_fixed_chunk\", corpus.chunk(FixedSizeChunk(\"document\", 4, offset=-2))\n",
    ")\n",
    "\n",
    "corpus.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging\n",
    "If you have multiple `Corpus` objects that share compatible atoms types (e.g. you created corpora for the same kinds of documents from two different sources), they can be merged into a single, larger corpus with `Corpus.merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<retrievall.core.Corpus at 0x10e5396f0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually set up another corpus\n",
    "atoms_2 = pa.Table.from_pydict(\n",
    "    {\n",
    "        \"id\": [987, 654, 999, 765],  # Better be distinct from the other corpus!\n",
    "        \"text\": [\"Some\", \"other\", \"little\", \"doc\"],\n",
    "        \"ordinal\": [1, 2, 3, 4],\n",
    "    }\n",
    ")\n",
    "\n",
    "corpus_2 = Corpus(atoms=atoms_2)\n",
    "\n",
    "# Also include some doc chunks\n",
    "corpus_2.set_chunk(\n",
    "    name=\"document\",\n",
    "    chunks=Chunks(\n",
    "        corpus=corpus_2,\n",
    "        chunks=pa.Table.from_pydict({\"id\": [4321]}),  # Needs to be distinct!\n",
    "        chunk_atoms=pa.Table.from_pydict(\n",
    "            {\"chunk\": [4321, 4321, 4321, 4321], \"atom\": [987, 654, 999, 765]}\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# We also need to have the same persistent chunk types\n",
    "corpus_2.set_chunk(\n",
    "    \"my_fixed_chunk\", corpus_2.chunk(FixedSizeChunk(\"document\", 4, offset=-2))\n",
    ")\n",
    "\n",
    "corpus_2  # New corpus, similar to the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<retrievall.core.Corpus at 0x10f646e90>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = Corpus.merge([corpus, corpus_2])  # New, combined corpus!\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have more `my_fixed_chunks` than before (because of the merge)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged.chunk(\"my_fixed_chunk\"))"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
